# Base configuration defaults
defaults:
  # Model defaults
  model:
    torch_dtype: "auto"  # Will be float16 for CUDA, float32 otherwise
    load_in_8bit: false
    device: "auto"  # Will try CUDA → MPS → CPU in that order
    
  # Training defaults  
  training:
    num_soft_prompt_tokens: 8
    learning_rate: 0.0001
    batch_size: 4
    gradient_accumulation_steps: 2
    num_epochs: 10
    max_grad_norm: 1.0
    warmup_steps: 100
    seed: 42
    mixed_precision: true
    gradient_checkpointing: false
    early_stopping_patience: 3
    logging_steps: 10
    eval_steps: 100
    save_steps: 500
    max_length: 512

  # Generation defaults
  generation:
    max_length: 128
    num_generations_per_prompt: 10
    temperature: 0.7
    top_p: 1.0
    top_k: 50
    do_sample: true
    num_beams: 1

  # Data processing defaults
  data:
    train_split: 0.9
    min_text_length: 10
    max_text_length: 150
    max_texts_per_category: 1000
