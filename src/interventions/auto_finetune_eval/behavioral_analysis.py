"""
This module contains functions for analyzing behavioral patterns in model outputs.
"""

import json
import random
from typing import List, Dict, Any, Optional, Tuple, Union

def analyze_behavioral_patterns(
    base_decoded_texts: List[str],
    finetuned_decoded_texts: List[str],
    base_clustering: Any,
    finetuned_clustering: Any,
    base_labels: Dict[int, Tuple[str, float]],
    finetuned_labels: Dict[int, Tuple[str, float]],
    api_provider: str = "anthropic",
    api_model_str: str = "claude-3-haiku-20240307",
    auth_key: Optional[str] = None,
    client: Optional[Any] = None
) -> Dict[str, Any]:
    """
    Analyze behavioral patterns in chain-of-thought reasoning between base and finetuned models.
    
    Args:
        base_decoded_texts: Texts generated by the base model
        finetuned_decoded_texts: Texts generated by the finetuned model
        base_clustering: Clustering results for the base model
        finetuned_clustering: Clustering results for the finetuned model
        base_labels: Labels for base model clusters
        finetuned_labels: Labels for finetuned model clusters
        api_provider: Provider for the API model
        api_model_str: Model name for the API
        auth_key: Authentication key for the API
        client: Client object for the API
    
    Returns:
        Dictionary containing analysis of behavioral patterns
    """
    from behavioural_clustering.models.model_factory import initialize_model
    
    model_info = {
        "model_family": api_provider,
        "model_name": api_model_str,
        "system_message": "You are an expert in analyzing patterns in language model outputs, particularly in chain-of-thought reasoning."
    }
    
    llm = initialize_model(model_info)
    
    base_samples = {}
    for cluster_id in set(base_clustering.labels_):
        if cluster_id == -1:  # Skip noise cluster if using HDBSCAN
            continue
        indices = [i for i, label in enumerate(base_clustering.labels_) if label == cluster_id]
        sample_indices = random.sample(indices, min(5, len(indices)))
        base_samples[cluster_id] = [base_decoded_texts[i] for i in sample_indices]
    
    finetuned_samples = {}
    for cluster_id in set(finetuned_clustering.labels_):
        if cluster_id == -1:  # Skip noise cluster if using HDBSCAN
            continue
        indices = [i for i, label in enumerate(finetuned_clustering.labels_) if label == cluster_id]
        sample_indices = random.sample(indices, min(5, len(indices)))
        finetuned_samples[cluster_id] = [finetuned_decoded_texts[i] for i in sample_indices]
    
    base_cluster_labels = {str(cluster_id): label for cluster_id, (label, _) in base_labels.items() 
                          if cluster_id in base_samples}
    finetuned_cluster_labels = {str(cluster_id): label for cluster_id, (label, _) in finetuned_labels.items() 
                               if cluster_id in finetuned_samples}
    
    prompt = f"""Analyze the following examples of chain-of-thought reasoning from two different models.

Base Model Clusters and their labels:
"""
    
    for cluster_id, samples in base_samples.items():
        if str(cluster_id) in base_cluster_labels:
            prompt += f"\nCluster {cluster_id} - Label: {base_cluster_labels[str(cluster_id)]}\n"
            for i, sample in enumerate(samples[:3]):  # Limit to 3 samples per cluster to avoid token limits
                prompt += f"Sample {i+1}: {sample[:200]}...\n"  # Truncate long samples
    
    prompt += f"\nFinetuned Model Clusters and their labels:\n"
    
    for cluster_id, samples in finetuned_samples.items():
        if str(cluster_id) in finetuned_cluster_labels:
            prompt += f"\nCluster {cluster_id} - Label: {finetuned_cluster_labels[str(cluster_id)]}\n"
            for i, sample in enumerate(samples[:3]):  # Limit to 3 samples per cluster to avoid token limits
                prompt += f"Sample {i+1}: {sample[:200]}...\n"  # Truncate long samples
    
    prompt += """
Identify key behavioral differences in how these models approach problem-solving. Focus on:
1. Differences in reasoning patterns
2. Variations in problem-solving strategies
3. Differences in the types of information considered
4. Variations in how conclusions are reached
5. Any identifiable biases or preferences in reasoning

Provide a detailed analysis with specific examples. Format your response as a JSON object with the following structure:
{
  "key_behavioral_differences": [
    {"category": "reasoning_pattern", "description": "...", "examples": ["...", "..."]},
    {"category": "problem_solving", "description": "...", "examples": ["...", "..."]},
    ...
  ],
  "summary": "..."
}
"""
    
    analysis_text = llm.generate(prompt)
    
    try:
        analysis_json = json.loads(analysis_text)
    except json.JSONDecodeError:
        analysis_json = {"raw_analysis": analysis_text}
    
    return {
        "behavioral_analysis": analysis_json,
        "base_samples": base_samples,
        "finetuned_samples": finetuned_samples,
        "base_cluster_labels": base_cluster_labels,
        "finetuned_cluster_labels": finetuned_cluster_labels
    }
